# RAG System Configuration
paths:
  data_dir: "data"
  prompt_path: "prompts"

ui:
  default_backend: "gemini"

llm:
  gemini:
    # API key is read from .streamlit/secrets.toml
    model: "gemini-2.0-flash"
    temperature: 0.7
    max_tokens: 2048

  lmstudio:
    base_url: http://127.0.0.1:1234/v1
    api_key:
      env: LMSTUDIO_API_KEY
      default: lm-studio  # local default; override in env for prod
    model: google/gemma-3-4b
    sampling:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 2048