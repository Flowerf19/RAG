#!/usr/bin/env python3
"""
Test há»‡ thá»‘ng RAG vá»›i 15 cÃ¢u há»i vá» RAG vÃ  Reranker
"""

import sys
import os
import json
from pathlib import Path

# Add current directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

try:
    from pipeline.backend_connector import fetch_retrieval
    from llm.chat_handler import build_messages
    from llm.LLM_API import call_gemini
    print("âœ… All imports successful")
except ImportError as e:
    print(f"âŒ Import failed: {e}")
    sys.exit(1)

# 15 cÃ¢u há»i test
TEST_QUESTIONS = [
    {
        "id": 1,
        "question": "Giáº£i thÃ­ch vai trÃ² cá»§a Reranker trong quy trÃ¬nh truy xuáº¥t tÄƒng cÆ°á»ng tháº¿ há»‡ (RAG) hai giai Ä‘oáº¡n. Táº¡i sao giai Ä‘oáº¡n reranking láº¡i Ä‘áº·c biá»‡t quan trá»ng Ä‘á»‘i vá»›i sá»± hÃ i lÃ²ng cá»§a ngÆ°á»i dÃ¹ng?",
        "topic": "Vai trÃ² cá»§a Reranker trong Kiáº¿n trÃºc RAG"
    },
    {
        "id": 2,
        "question": "MÃ´ táº£ sá»± khÃ¡c biá»‡t cá»‘t lÃµi trong cÃ¡ch cross-encoder (nhÆ° BGE Reranker hoáº·c ViRanker) vÃ  bi-encoder xá»­ lÃ½ cáº·p truy váº¥nâ€“tÃ i liá»‡u (queryâ€“document) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan.",
        "topic": "Sá»± khÃ¡c biá»‡t cá»‘t lÃµi giá»¯a Cross-Encoder vÃ  Bi-Encoder"
    },
    {
        "id": 3,
        "question": "Hai sá»­a Ä‘á»•i kiáº¿n trÃºc chÃ­nh Ä‘Æ°á»£c Ã¡p dá»¥ng cho encoder ná»n táº£ng BGE-M3 Ä‘á»ƒ táº¡o ra ViRanker lÃ  gÃ¬, vÃ  sá»­a Ä‘á»•i nÃ o Ä‘Æ°á»£c thÃªm vÃ o Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t tÃ­nh toÃ¡n vÃ  xá»­ lÃ½ tÃ i liá»‡u dÃ i?",
        "topic": "Kiáº¿n trÃºc cá»‘t lÃµi cá»§a ViRanker"
    },
    {
        "id": 4,
        "question": "KÃ­ch thÆ°á»›c cá»§a kho ngá»¯ liá»‡u tiáº¿ng Viá»‡t Ä‘Æ°á»£c tuyá»ƒn chá»n (curated corpus) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã o táº¡o ViRanker lÃ  bao nhiÃªu, vÃ  mÃ´ hÃ¬nh nÃ y Ä‘Ã£ sá»­ dá»¥ng chiáº¿n lÆ°á»£c Hybrid Hard-Negative Mining bao gá»“m nhá»¯ng phÆ°Æ¡ng phÃ¡p truy xuáº¥t nÃ o?",
        "topic": "Dá»¯ liá»‡u vÃ  Chiáº¿n lÆ°á»£c Láº¥y máº«u Phá»§ Ä‘á»‹nh Cá»©ng cá»§a ViRanker"
    },
    {
        "id": 5,
        "question": "Ká»¹ thuáº­t Hybrid Retrieval (Truy xuáº¥t Lai) káº¿t há»£p nhá»¯ng phÆ°Æ¡ng phÃ¡p tÃ¬m kiáº¿m nÃ o, vÃ  hai lá»£i Ã­ch chÃ­nh mÃ  nÃ³ mang láº¡i cho há»‡ thá»‘ng RAG lÃ  gÃ¬?",
        "topic": "Ká»¹ thuáº­t Hybrid Retrieval trong RAG"
    },
    {
        "id": 6,
        "question": "ViRanker Ä‘áº¡t Ä‘Æ°á»£c nhá»¯ng Ä‘iá»ƒm sá»‘ NDCG@3 vÃ  MRR@3 nÃ o trÃªn bá»™ benchmark MMARCO-VI? Theo tÃ i liá»‡u, so vá»›i PhoRanker, ViRanker thá»ƒ hiá»‡n Æ°u tháº¿ á»Ÿ loáº¡i truy váº¥n nÃ o, vÃ  PhoRanker giá»¯ lá»£i tháº¿ á»Ÿ loáº¡i truy váº¥n nÃ o?",
        "topic": "Hiá»‡u suáº¥t vÃ  So sÃ¡nh giá»¯a ViRanker vÃ  PhoRanker"
    },
    {
        "id": 7,
        "question": "Theo tÃ i liá»‡u, hai loáº¡i váº¥n Ä‘á»/truy váº¥n chÃ­nh thÆ°á»ng dáº«n Ä‘áº¿n lá»—i (failures) cho ViRanker trÃªn táº­p dá»¯ liá»‡u MMARCO-VI lÃ  gÃ¬?",
        "topic": "PhÃ¢n tÃ­ch lá»—i cá»§a ViRanker"
    },
    {
        "id": 8,
        "question": "Jina Reranker v2 ná»•i báº­t so vá»›i cÃ¡c reranker khÃ¡c (nhÆ° BGE-reranker-v2-m3) á»Ÿ khÃ­a cáº¡nh nÃ o liÃªn quan Ä‘áº¿n tá»‘c Ä‘á»™ vÃ  kháº£ nÄƒng xá»­ lÃ½ ngá»¯ cáº£nh dÃ i (long context)?",
        "topic": "Æ¯u Ä‘iá»ƒm ná»•i báº­t vá» Hiá»‡u suáº¥t cá»§a Jina Reranker v2"
    },
    {
        "id": 9,
        "question": "Liá»‡t kÃª ba lÃ½ do cá»‘t lÃµi khiáº¿n kiáº¿n trÃºc RAG cÆ¡ báº£n ('chunk documents â†’ embed them â†’ store in a vector database â†’ retrieve top-k similar chunks') thÆ°á»ng tháº¥t báº¡i trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿.",
        "topic": "Táº¡i sao RAG CÆ¡ báº£n tháº¥t báº¡i"
    },
    {
        "id": 10,
        "question": "Ká»¹ thuáº­t PageIndex giáº£i quyáº¿t váº¥n Ä‘á» gÃ¬ cá»§a RAG cÆ¡ báº£n, vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a nÃ³ mÃ´ phá»ng cÃ¡ch con ngÆ°á»i duyá»‡t tÃ i liá»‡u nhÆ° tháº¿ nÃ o?",
        "topic": "Ká»¹ thuáº­t PageIndex"
    },
    {
        "id": 11,
        "question": "Cache-Augmented Generation (CAG) hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o Ä‘á»ƒ tá»‘i Æ°u hÃ³a chi phÃ­ vÃ  Ä‘á»™ trá»… cho há»‡ thá»‘ng RAG? Ká»¹ thuáº­t nÃ y thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng cho loáº¡i dá»¯ liá»‡u nÃ o?",
        "topic": "Ká»¹ thuáº­t Cache-Augmented Generation (CAG)"
    },
    {
        "id": 12,
        "question": "Ká»¹ thuáº­t Self-Reasoning (Tá»± LÃ½ luáº­n) chuyá»ƒn Ä‘á»•i há»‡ thá»‘ng RAG tá»« má»™t cÃ´ng cá»¥ thá»¥ Ä‘á»™ng thÃ nh má»™t tÃ¡c nhÃ¢n nhÆ° tháº¿ nÃ o, vÃ  lá»£i Ã­ch chÃ­nh cá»§a nÃ³ Ä‘á»‘i vá»›i Ä‘áº§u ra cá»§a LLM lÃ  gÃ¬?",
        "topic": "Ká»¹ thuáº­t Self-Reasoning"
    },
    {
        "id": 13,
        "question": "Má»¥c Ä‘Ã­ch cá»§a ká»¹ thuáº­t Multivector Retrieval lÃ  gÃ¬, vÃ  nÃ³ giáº£i quyáº¿t háº¡n cháº¿ nÃ o cá»§a tÃ¬m kiáº¿m vector truyá»n thá»‘ng?",
        "topic": "Ká»¹ thuáº­t Multivector Retrieval"
    },
    {
        "id": 14,
        "question": "Adaptive RAG (RAG ThÃ­ch á»©ng) xá»­ lÃ½ cÃ¡c truy váº¥n Ä‘Æ¡n giáº£n vÃ  phá»©c táº¡p khÃ¡c nhau nhÆ° tháº¿ nÃ o, vÃ  lá»£i Ã­ch mÃ  ká»¹ thuáº­t nÃ y mang láº¡i?",
        "topic": "Ká»¹ thuáº­t Adaptive RAG (RAG ThÃ­ch á»©ng)"
    },
    {
        "id": 15,
        "question": "NgoÃ i cÃ¡c sá»‘ liá»‡u xáº¿p háº¡ng truyá»n thá»‘ng (nhÆ° NDCG), hÃ£y Ä‘á»‹nh nghÄ©a vÃ  giáº£i thÃ­ch Ã½ nghÄ©a cá»§a hai sá»‘ liá»‡u quan trá»ng sau Ä‘á»ƒ Ä‘o lÆ°á»ng cháº¥t lÆ°á»£ng Ä‘áº§u ra cá»§a LLM trong RAG: Faithfulness (TÃ­nh Trung thá»±c) vÃ  Context Precision (Äá»™ chÃ­nh xÃ¡c Ngá»¯ cáº£nh).",
        "topic": "CÃ¡c Sá»‘ liá»‡u ÄÃ¡nh giÃ¡ ChÃ­nh trong RAG"
    }
]

def test_rag_system():
    """Test há»‡ thá»‘ng RAG vá»›i 15 cÃ¢u há»i"""
    results = []

    print("ðŸš€ Testing RAG System with 15 Questions")
    print("=" * 60)

    for i, test_case in enumerate(TEST_QUESTIONS, 1):
        question_id = test_case["id"]
        question = test_case["question"]
        topic = test_case["topic"]

        print(f"\nðŸ“‹ Question {question_id}: {topic}")
        print(f"â“ {question[:100]}{'...' if len(question) > 100 else ''}")

        try:
            # Step 1: Get retrieval data
            print("ðŸ” Retrieving context...")
            ret = fetch_retrieval(question, top_k=10, max_chars=8000)
            context = ret.get("context", "") or ""
            sources = ret.get("sources", [])

            print(f"   ðŸ“„ Context: {len(context)} chars")
            print(f"   ðŸ“š Sources: {len(sources)} items")

            # Step 2: Build messages and call LLM
            print("ðŸ¤– Generating answer...")
            messages = build_messages(
                query=question,
                context=context,
                history=[]
            )

            response = call_gemini(messages)

            print(f"   ðŸ’¬ Response: {len(response)} chars")

            # Store result
            result = {
                "id": question_id,
                "topic": topic,
                "question": question,
                "context_length": len(context),
                "sources_count": len(sources),
                "response_length": len(response),
                "response_preview": response[:200] + "..." if len(response) > 200 else response,
                "top_sources": [
                    {
                        "file": src.get("file_name", ""),
                        "page": src.get("page_number", ""),
                        "score": src.get("similarity_score", 0)
                    } for src in sources[:3]  # Top 3 sources
                ]
            }

            results.append(result)

            print("   âœ… Success")

        except Exception as e:
            print(f"   âŒ Failed: {e}")
            results.append({
                "id": question_id,
                "topic": topic,
                "question": question,
                "error": str(e)
            })

    return results

def save_results(results, filename="rag_test_results.json"):
    """Save test results to JSON file"""
    output_path = Path(filename)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nðŸ’¾ Results saved to {output_path}")

def print_summary(results):
    """Print test summary"""
    successful = len([r for r in results if "error" not in r])
    failed = len([r for r in results if "error" in r])

    print(f"\nðŸ“Š Test Summary:")
    print(f"   âœ… Successful: {successful}/15")
    print(f"   âŒ Failed: {failed}/15")

    if successful > 0:
        avg_context = sum(r.get("context_length", 0) for r in results if "error" not in r) / successful
        avg_response = sum(r.get("response_length", 0) for r in results if "error" not in r) / successful
        avg_sources = sum(r.get("sources_count", 0) for r in results if "error" not in r) / successful

        print(f"   ðŸ“„ Average context length: {avg_context:.0f} chars")
        print(f"   ðŸ’¬ Average response length: {avg_response:.0f} chars")
        print(f"   ðŸ“š Average sources count: {avg_sources:.1f}")

if __name__ == "__main__":
    results = test_rag_system()
    save_results(results)
    print_summary(results)
    print("\nðŸŽ‰ RAG System Testing Complete!")